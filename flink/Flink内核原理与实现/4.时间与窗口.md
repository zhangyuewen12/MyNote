# 一、时间类型

Flink定义了三种时间类型：时间时间、处理时间、摄取时间

> **Processing time:** Processing time refers to the system time of the machine that is executing the respective operation.
>
> **Event time:** Event time is the time that each individual event occurred on its producing device. 



# 二、窗口

> 窗口的本质是对数据的切分。Flink提供了3类默认窗口：计数窗口、时间窗口和会话窗口。





## 2.0 窗口分类

> #### 时间窗口
>
> 按时间类型分:处理时间窗口和事件时间窗口
>
> 按行为类型分:滚动窗口和滑动窗口
>
> ### 会话窗口
>
> ### 计数窗口



## 2.1 窗口流程



> WindowAssigner: 窗口算子负责处理窗口，数据不断进入算子，每一个数据元素进入算子时，首先会被交给WindowAssigner，其决定元素会被放入到哪个或哪些窗口，在这个过程中可能会创建新的窗口或合并旧的窗口。
>
> Window: window本身只是一个ID标识符，其内部可能存储了一些元数据，如TimeWindow中有开始和结束时间。但是并不会存储窗口中的元素。窗口中的元素实际存储在Key/Value State中。Key是window,Value是数据集合。
>
> Trigger：每一个窗口都依赖于Trigger，Trigger上有定时器，用来决定一个窗口何时能够被计算或清除。每当有元素被分配到该窗口，或者之前注册的定时器超时时，Trigger都会被调用。
>
> Evictor:Trigger被触发后，窗口中的元素集合就会交给Evictor,Evictor主要是用来遍历窗口中的元素列表，并决定最先进入窗口的多少个元素需要被移除。剩余的交给用户指定的函数进行计算。如果没有Evictor，窗口中所有的元素都会交给函数计算。
>
> 函数:函数会计算出窗口的结果值，并送给下游。窗口的结果值可以是一个、或者多个。DataStream API 上可以接受不同的计算函数。



Windows are at the heart of processing infinite streams. Windows split the stream into “buckets” of finite size, over which we can apply computations. This document focuses on how windowing is performed in Flink and how the programmer can benefit to the maximum from its offered functionality.

The general structure of a windowed Flink program is presented below. The first snippet refers to *keyed* streams, while the second to *non-keyed* ones. As one can see, the only difference is the `keyBy(...)` call for the keyed streams and the `window(...)` which becomes `windowAll(...)` for non-keyed streams. This is also going to serve as a roadmap for the rest of the page.



```
Keyed Windows
stream
       .keyBy(...)               <-  keyed versus non-keyed windows
       .window(...)              <-  required: "assigner"
      [.trigger(...)]            <-  optional: "trigger" (else default trigger)
      [.evictor(...)]            <-  optional: "evictor" (else no evictor)
      [.allowedLateness(...)]    <-  optional: "lateness" (else zero)
      [.sideOutputLateData(...)] <-  optional: "output tag" (else no side output for late data)
       .reduce/aggregate/apply()      <-  required: "function"
      [.getSideOutput(...)]      <-  optional: "output tag"

Non-Keyed Windows
stream
       .windowAll(...)           <-  required: "assigner"
      [.trigger(...)]            <-  optional: "trigger" (else default trigger)
      [.evictor(...)]            <-  optional: "evictor" (else no evictor)
      [.allowedLateness(...)]    <-  optional: "lateness" (else zero)
      [.sideOutputLateData(...)] <-  optional: "output tag" (else no side output for late data)
       .reduce/aggregate/apply()      <-  required: "function"
      [.getSideOutput(...)]      <-  optional: "output tag"

In the above, the commands in square brackets ([…]) are optional. This reveals that Flink allows you to customize your windowing logic in many different ways so that it best fits your needs.
```



## 2.2 窗口机制和原理



##### Window Assigner

> After specifying whether your stream is keyed or not, the next step is to define a *window assigner*. The window assigner defines how elements are assigned to windows. This is done by specifying the `WindowAssigner` of your choice in the `window(...)` (for *keyed* streams) or the `windowAll()` (for *non-keyed* streams) call.
>
> A `WindowAssigner` is responsible for assigning each incoming element to one or more windows. Flink comes with pre-defined window assigners for the most common use cases, namely *tumbling windows*, *sliding windows*, *session windows* and *global windows*. You can also implement a custom window assigner by extending the `WindowAssigner` class. All built-in window assigners (except the global windows) assign elements to windows based on time, which can either be processing time or event time. Please take a look at our section on [event time](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/concepts/time/) to learn about the difference between processing time and event time and how timestamps and watermarks are generated.
>
> Time-based windows have a *start timestamp* (inclusive) and an *end timestamp* (exclusive) that together describe the size of the window. In code, Flink uses `TimeWindow` when working with time-based windows which has methods for querying the start- and end-timestamp and also an additional method `maxTimestamp()` that returns the largest allowed timestamp for a given windows.
>
> In the following, we show how Flink’s pre-defined window assigners work and how they are used in a DataStream program. The following figures visualize the workings of each assigner. The purple circles represent elements of the stream, which are partitioned by some key (in this case *user 1*, *user 2* and *user 3*). The x-axis shows the progress of time.



##### Window Trigger

Trigger触发器决定了一个窗口何时能够被计算或清楚，**每一个窗口都拥有一个属于自己的Trigger.**

触发器触发的结果如下。

1. continue: 继续，不做任何处理。
2. Fire: 触发计算，处理窗口数据。
3. Purge: 触发清理，移除窗口和窗口中的数据。
4. Fire+Purge:触发计算+清理，处理数据并移除窗口和窗口中的数据。



在大数据中有3中典型的延迟计算：

1. 基于数据记录个数的触发，即等到Window中的数据达到一定个数，则触发窗口的计算，在类体系中对应的是CountTrigger。

2. 基于处理时间的触发：在处理时间维度判断哪些窗口需要触发，对应的是ProcessTimeTrigger。
3. 基于事件时间的触发：使用WaterMark机制。

> A `Trigger` determines when a window (as formed by the *window assigner*) is ready to be processed by the *window function*. Each `WindowAssigner` comes with a default `Trigger`. If the default trigger does not fit your needs, you can specify a custom trigger using `trigger(...)`.
>
> The trigger interface has five methods that allow a `Trigger` to react to different events:
>
> - The `onElement()` method is called for each element that is added to a window.
> - The `onEventTime()` method is called when a registered event-time timer fires.
> - The `onProcessingTime()` method is called when a registered processing-time timer fires.
> - The `onMerge()` method is relevant for stateful triggers and merges the states of two triggers when their corresponding windows merge, *e.g.* when using session windows.
> - Finally the `clear()` method performs any action needed upon removal of the corresponding window.
>
> Two things to notice about the above methods are:
>
> 1. The first three decide how to act on their invocation event by returning a `TriggerResult`. The action can be one of the following:
>
> - `CONTINUE`: do nothing,
> - `FIRE`: trigger the computation,
> - `PURGE`: clear the elements in the window, and
> - `FIRE_AND_PURGE`: trigger the computation and clear the elements in the window afterwards.
>
> 1. Any of these methods can be used to register processing- or event-time timers for future actions.
>
> ### Fire and Purge [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#fire-and-purge)
>
> Once a trigger determines that a window is ready for processing, it fires, *i.e.*, it returns `FIRE` or `FIRE_AND_PURGE`. This is the signal for the window operator to emit the result of the current window. Given a window with a `ProcessWindowFunction` all elements are passed to the `ProcessWindowFunction` (possibly after passing them to an evictor). Windows with `ReduceFunction`, or `AggregateFunction` simply emit their eagerly aggregated result.
>
> When a trigger fires, it can either `FIRE` or `FIRE_AND_PURGE`. While `FIRE` keeps the contents of the window, `FIRE_AND_PURGE` removes its content. By default, the pre-implemented triggers simply `FIRE` without purging the window state.
>
> > Purging will simply remove the contents of the window and will leave any potential meta-information about the window and any trigger state intact.
>
> ### Default Triggers of WindowAssigners [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#default-triggers-of-windowassigners)
>
> The default `Trigger` of a `WindowAssigner` is appropriate for many use cases. For example, all the event-time window assigners have an `EventTimeTrigger` as default trigger. This trigger simply fires once the watermark passes the end of a window.
>
> The default trigger of the `GlobalWindow` is the `NeverTrigger` which does never fire. Consequently, you always have to define a custom trigger when using a `GlobalWindow`.
>
> > By specifying a trigger using `trigger()` you are overwriting the default trigger of a `WindowAssigner`. For example, if you specify a `CountTrigger` for `TumblingEventTimeWindows` you will no longer get window firings based on the progress of time but only by count. Right now, you have to write your own custom trigger if you want to react based on both time and count.
>
> ### Built-in and Custom Triggers [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#built-in-and-custom-triggers)
>
> Flink comes with a few built-in triggers.
>
> - The (already mentioned) `EventTimeTrigger` fires based on the progress of event-time as measured by watermarks.
> - The `ProcessingTimeTrigger` fires based on processing time.
> - The `CountTrigger` fires once the number of elements in a window exceeds the given limit.
> - The `PurgingTrigger` takes as argument another trigger and transforms it into a purging one.
>
> If you need to implement a custom trigger, you should check out the abstract [Trigger ](https://github.com/apache/flink/blob/release-1.15//flink-streaming-java/src/main/java/org/apache/flink/streaming/api/windowing/triggers/Trigger.java)class. Please note that the API is still evolving and might change in future versions of Flink.

```
package org.apache.flink.streaming.api.windowing.triggers;

import org.apache.flink.annotation.PublicEvolving;
import org.apache.flink.api.common.functions.RuntimeContext;
import org.apache.flink.api.common.state.MergingState;
import org.apache.flink.api.common.state.State;
import org.apache.flink.api.common.state.StateDescriptor;
import org.apache.flink.api.common.state.ValueState;
import org.apache.flink.api.common.typeinfo.TypeInformation;
import org.apache.flink.metrics.MetricGroup;
import org.apache.flink.streaming.api.windowing.windows.Window;

import java.io.Serializable;

/**
 * A {@code Trigger} determines when a pane of a window should be evaluated to emit the results for
 * that part of the window.
 *
 * <p>A pane is the bucket of elements that have the same key (assigned by the {@link
 * org.apache.flink.api.java.functions.KeySelector}) and same {@link Window}. An element can be in
 * multiple panes if it was assigned to multiple windows by the {@link
 * org.apache.flink.streaming.api.windowing.assigners.WindowAssigner}. These panes all have their
 * own instance of the {@code Trigger}.
 *
 * <p>Triggers must not maintain state internally since they can be re-created or reused for
 * different keys. All necessary state should be persisted using the state abstraction available on
 * the {@link TriggerContext}.
 *
 * <p>When used with a {@link
 * org.apache.flink.streaming.api.windowing.assigners.MergingWindowAssigner} the {@code Trigger}
 * must return {@code true} from {@link #canMerge()} and {@link #onMerge(Window, OnMergeContext)}
 * most be properly implemented.
 *
 * @param <T> The type of elements on which this {@code Trigger} works.
 * @param <W> The type of {@link Window Windows} on which this {@code Trigger} can operate.
 */
@PublicEvolving
public abstract class Trigger<T, W extends Window> implements Serializable {

    private static final long serialVersionUID = -4104633972991191369L;

    /**
     * Called for every element that gets added to a pane. The result of this will determine whether
     * the pane is evaluated to emit results.
     *
     * @param element The element that arrived.
     * @param timestamp The timestamp of the element that arrived.
     * @param window The window to which the element is being added.
     * @param ctx A context object that can be used to register timer callbacks.
     */
    public abstract TriggerResult onElement(T element, long timestamp, W window, TriggerContext ctx)
            throws Exception;

    /**
     * Called when a processing-time timer that was set using the trigger context fires.
     *
     * @param time The timestamp at which the timer fired.
     * @param window The window for which the timer fired.
     * @param ctx A context object that can be used to register timer callbacks.
     */
    public abstract TriggerResult onProcessingTime(long time, W window, TriggerContext ctx)
            throws Exception;

    /**
     * Called when an event-time timer that was set using the trigger context fires.
     *
     * @param time The timestamp at which the timer fired.
     * @param window The window for which the timer fired.
     * @param ctx A context object that can be used to register timer callbacks.
     */
    public abstract TriggerResult onEventTime(long time, W window, TriggerContext ctx)
            throws Exception;

    /**
     * Returns true if this trigger supports merging of trigger state and can therefore be used with
     * a {@link org.apache.flink.streaming.api.windowing.assigners.MergingWindowAssigner}.
     *
     * <p>If this returns {@code true} you must properly implement {@link #onMerge(Window,
     * OnMergeContext)}
     */
    public boolean canMerge() {
        return false;
    }

    /**
     * Called when several windows have been merged into one window by the {@link
     * org.apache.flink.streaming.api.windowing.assigners.WindowAssigner}.
     *
     * @param window The new window that results from the merge.
     * @param ctx A context object that can be used to register timer callbacks and access state.
     */
    public void onMerge(W window, OnMergeContext ctx) throws Exception {
        throw new UnsupportedOperationException("This trigger does not support merging.");
    }

    /**
     * Clears any state that the trigger might still hold for the given window. This is called when
     * a window is purged. Timers set using {@link TriggerContext#registerEventTimeTimer(long)} and
     * {@link TriggerContext#registerProcessingTimeTimer(long)} should be deleted here as well as
     * state acquired using {@link TriggerContext#getPartitionedState(StateDescriptor)}.
     */
    public abstract void clear(W window, TriggerContext ctx) throws Exception;

    // ------------------------------------------------------------------------

    /**
     * A context object that is given to {@link Trigger} methods to allow them to register timer
     * callbacks and deal with state.
     */
    public interface TriggerContext {

        /** Returns the current processing time. */
        long getCurrentProcessingTime();

        /**
         * Returns the metric group for this {@link Trigger}. This is the same metric group that
         * would be returned from {@link RuntimeContext#getMetricGroup()} in a user function.
         *
         * <p>You must not call methods that create metric objects (such as {@link
         * MetricGroup#counter(int)} multiple times but instead call once and store the metric
         * object in a field.
         */
        MetricGroup getMetricGroup();

        /** Returns the current watermark time. */
        long getCurrentWatermark();

        /**
         * Register a system time callback. When the current system time passes the specified time
         * {@link Trigger#onProcessingTime(long, Window, TriggerContext)} is called with the time
         * specified here.
         *
         * @param time The time at which to invoke {@link Trigger#onProcessingTime(long, Window,
         *     TriggerContext)}
         */
        void registerProcessingTimeTimer(long time);

        /**
         * Register an event-time callback. When the current watermark passes the specified time
         * {@link Trigger#onEventTime(long, Window, TriggerContext)} is called with the time
         * specified here.
         *
         * @param time The watermark at which to invoke {@link Trigger#onEventTime(long, Window,
         *     TriggerContext)}
         * @see org.apache.flink.streaming.api.watermark.Watermark
         */
        void registerEventTimeTimer(long time);

        /** Delete the processing time trigger for the given time. */
        void deleteProcessingTimeTimer(long time);

        /** Delete the event-time trigger for the given time. */
        void deleteEventTimeTimer(long time);

        /**
         * Retrieves a {@link State} object that can be used to interact with fault-tolerant state
         * that is scoped to the window and key of the current trigger invocation.
         *
         * @param stateDescriptor The StateDescriptor that contains the name and type of the state
         *     that is being accessed.
         * @param <S> The type of the state.
         * @return The partitioned state object.
         * @throws UnsupportedOperationException Thrown, if no partitioned state is available for
         *     the function (function is not part os a KeyedStream).
         */
        <S extends State> S getPartitionedState(StateDescriptor<S, ?> stateDescriptor);

        /**
         * Retrieves a {@link ValueState} object that can be used to interact with fault-tolerant
         * state that is scoped to the window and key of the current trigger invocation.
         *
         * @param name The name of the key/value state.
         * @param stateType The class of the type that is stored in the state. Used to generate
         *     serializers for managed memory and checkpointing.
         * @param defaultState The default state value, returned when the state is accessed and no
         *     value has yet been set for the key. May be null.
         * @param <S> The type of the state.
         * @return The partitioned state object.
         * @throws UnsupportedOperationException Thrown, if no partitioned state is available for
         *     the function (function is not part os a KeyedStream).
         * @deprecated Use {@link #getPartitionedState(StateDescriptor)}.
         */
        @Deprecated
        <S extends Serializable> ValueState<S> getKeyValueState(
                String name, Class<S> stateType, S defaultState);

        /**
         * Retrieves a {@link ValueState} object that can be used to interact with fault-tolerant
         * state that is scoped to the window and key of the current trigger invocation.
         *
         * @param name The name of the key/value state.
         * @param stateType The type information for the type that is stored in the state. Used to
         *     create serializers for managed memory and checkpoints.
         * @param defaultState The default state value, returned when the state is accessed and no
         *     value has yet been set for the key. May be null.
         * @param <S> The type of the state.
         * @return The partitioned state object.
         * @throws UnsupportedOperationException Thrown, if no partitioned state is available for
         *     the function (function is not part os a KeyedStream).
         * @deprecated Use {@link #getPartitionedState(StateDescriptor)}.
         */
        @Deprecated
        <S extends Serializable> ValueState<S> getKeyValueState(
                String name, TypeInformation<S> stateType, S defaultState);
    }

    /**
     * Extension of {@link TriggerContext} that is given to {@link Trigger#onMerge(Window,
     * OnMergeContext)}.
     */
    public interface OnMergeContext extends TriggerContext {
        <S extends MergingState<?, ?>> void mergePartitionedState(
                StateDescriptor<S, ?> stateDescriptor);
    }
}


```



##### WindowEvictor



> ## Evictors [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#evictors)
>
> Flink’s windowing model allows specifying an optional `Evictor` in addition to the `WindowAssigner` and the `Trigger`. This can be done using the `evictor(...)` method (shown in the beginning of this document). The evictor has the ability to remove elements from a window *after* the trigger fires and *before and/or after* the window function is applied. To do so, the `Evictor` interface has two methods:
>
> ```
> /**
>  * Optionally evicts elements. Called before windowing function.
>  *
>  * @param elements The elements currently in the pane.
>  * @param size The current number of elements in the pane.
>  * @param window The {@link Window}
>  * @param evictorContext The context for the Evictor
>  */
> void evictBefore(Iterable<TimestampedValue<T>> elements, int size, W window, EvictorContext evictorContext);
> 
> /**
>  * Optionally evicts elements. Called after windowing function.
>  *
>  * @param elements The elements currently in the pane.
>  * @param size The current number of elements in the pane.
>  * @param window The {@link Window}
>  * @param evictorContext The context for the Evictor
>  */
> void evictAfter(Iterable<TimestampedValue<T>> elements, int size, W window, EvictorContext evictorContext);
> ```
>
>  
>
> The `evictBefore()` contains the eviction logic to be applied before the window function, while the `evictAfter()` contains the one to be applied after the window function. Elements evicted before the application of the window function will not be processed by it.
>
> Flink comes with three pre-implemented evictors. These are:
>
> - `CountEvictor`: keeps up to a user-specified number of elements from the window and discards the remaining ones from the beginning of the window buffer.
> - `DeltaEvictor`: takes a `DeltaFunction` and a `threshold`, computes the delta between the last element in the window buffer and each of the remaining ones, and removes the ones with a delta greater or equal to the threshold.
> - `TimeEvictor`: takes as argument an `interval` in milliseconds and for a given window, it finds the maximum timestamp `max_ts` among its elements and removes all the elements with timestamps smaller than `max_ts - interval`.
>
> By default, all the pre-implemented evictors apply their logic before the window function.





##### Allowed Lateness

> When working with *event-time* windowing, it can happen that elements arrive late, *i.e.* the watermark that Flink uses to keep track of the progress of event-time is already past the end timestamp of a window to which an element belongs. See [event time](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/generating_watermarks/) and especially [late elements](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/generating_watermarks/#late-elements) for a more thorough discussion of how Flink deals with event time.
>
> By default, late elements are dropped when the watermark is past the end of the window. However, Flink allows to specify a maximum *allowed lateness* for window operators. Allowed lateness specifies by how much time elements can be late before they are dropped, and its default value is 0. Elements that arrive after the watermark has passed the end of the window but before it passes the end of the window plus the allowed lateness, are still added to the window. Depending on the trigger used, a late but not dropped element may cause the window to fire again. This is the case for the `EventTimeTrigger`.
>
> In order to make this work, Flink keeps the state of windows until their allowed lateness expires. Once this happens, Flink removes the window and deletes its state, as also described in the [Window Lifecycle](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#window-lifecycle) section.
>
> By default, the allowed lateness is set to `0`. That is, elements that arrive behind the watermark will be dropped.
>
> You can specify an allowed lateness like this:
>
> ```
> DataStream<T> input = ...;
> 
> input
>     .keyBy(<key selector>)
>     .window(<window assigner>)
>     .allowedLateness(<time>)
>     .<windowed transformation>(<window function>);
> ```
>
> 
>
> ### Getting late data as a side output [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#getting-late-data-as-a-side-output)
>
> Using Flink’s [side output](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/side_output/) feature you can get a stream of the data that was discarded as late.
>
> You first need to specify that you want to get late data using `sideOutputLateData(OutputTag)` on the windowed stream. Then, you can get the side-output stream on the result of the windowed operation:
>
> ```java
> final OutputTag<T> lateOutputTag = new OutputTag<T>("late-data"){};
> 
> DataStream<T> input = ...;
> 
> SingleOutputStreamOperator<T> result = input
>     .keyBy(<key selector>)
>     .window(<window assigner>)
>     .allowedLateness(<time>)
>     .sideOutputLateData(lateOutputTag)
>     .<windowed transformation>(<window function>);
> 
> DataStream<T> lateStream = result.getSideOutput(lateOutputTag);
> ```



## 2.3 窗口实现

##### 滚动窗口

关键属性: offset 窗口的起始时间和Size 窗口的大小

> ### Tumbling Windows
>
> A *tumbling windows* assigner assigns each element to a window of a specified *window size*. Tumbling windows have a fixed size and do not overlap. For example, if you specify a tumbling window with a size of 5 minutes, the current window will be evaluated and a new window will be started every five minutes as illustrated by the following figure.

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20220824100430189.png" alt="image-20220824100430189" style="zoom:50%;" />



分类: 滚动时间窗口和滑动时间窗口 ，使用如下：

```java
DataStream<T> input = ...;

// tumbling event-time windows
input
    .keyBy(<key selector>)
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))
    .<windowed transformation>(<window function>);

// tumbling processing-time windows
input
    .keyBy(<key selector>)
    .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
    .<windowed transformation>(<window function>);

// daily tumbling event-time windows offset by -8 hours.
input
    .keyBy(<key selector>)
    .window(TumblingEventTimeWindows.of(Time.days(1), Time.hours(-8)))
    .<windowed transformation>(<window function>);
```

> Time intervals can be specified by using one of `Time.milliseconds(x)`, `Time.seconds(x)`, `Time.minutes(x)`, and so on.
>
> As shown in the last example, tumbling window assigners also take an optional `offset` parameter that can be used to change the alignment of windows. For example, without offsets hourly tumbling windows are aligned with epoch, that is you will get windows such as `1:00:00.000 - 1:59:59.999`, `2:00:00.000 - 2:59:59.999` and so on. If you want to change that you can give an offset. With an offset of 15 minutes you would, for example, get `1:15:00.000 - 2:14:59.999`, `2:15:00.000 - 3:14:59.999` etc. An important use case for offsets is to adjust windows to timezones other than UTC-0. For example, in China you would have to specify an offset of `Time.hours(-8)`.



##### 滑动窗口

**关键属性: Offset 窗口的起始时间 、Size 窗口的长度 和Slide 窗口的滑动距离**

> ### Sliding Windows [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#sliding-windows)
>
> The *sliding windows* assigner assigns elements to windows of fixed length. Similar to a tumbling windows assigner, the size of the windows is configured by the *window size* parameter. An additional *window slide* parameter controls how frequently a sliding window is started. Hence, sliding windows can be overlapping if the slide is smaller than the window size. In this case elements are assigned to multiple windows.
>
> For example, you could have windows of size 10 minutes that slides by 5 minutes. With this you get every 5 minutes a window that contains the events that arrived during the last 10 minutes as depicted by the following figure.



<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20220824101255936.png" alt="image-20220824101255936" style="zoom:50%;" />

**分类: 处理时间窗口和时间时间窗口,使用如下：**



```java
DataStream<T> input = ...;

// sliding event-time windows
input
    .keyBy(<key selector>)
    .window(SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5)))
    .<windowed transformation>(<window function>);

// sliding processing-time windows
input
    .keyBy(<key selector>)
    .window(SlidingProcessingTimeWindows.of(Time.seconds(10), Time.seconds(5)))
    .<windowed transformation>(<window function>);

// sliding processing-time windows offset by -8 hours
input
    .keyBy(<key selector>)
    .window(SlidingProcessingTimeWindows.of(Time.hours(12), Time.hours(1), Time.hours(-8)))
    .<windowed transformation>(<window function>);
```



##### 会话窗口

> ### Session Windows [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#session-windows)
>
> The *session windows* assigner groups elements by sessions of activity. Session windows do not overlap and do not have a fixed start and end time, in contrast to *tumbling windows* and *sliding windows*. Instead a session window closes when it does not receive elements for a certain period of time, *i.e.*, when a gap of inactivity occurred. A session window assigner can be configured with either a static *session gap* or with a *session gap extractor* function which defines how long the period of inactivity is. When this period expires, the current session closes and subsequent elements are assigned to a new session window.
>
> 1. 会话窗口不会重叠，也不会有固定的开始和结束时间
>
> 2. 会话窗口的关闭条件是：在固定时间内没有输入元素或者满足会话函数条件。
>
> 3. 会话窗口不同于时间窗口，它的切分依赖于事件的行为，和不是时间序列，所在在很多情况下会因为时间乱序使得原来相互独立的窗口因为新事件的到来导致窗口重叠，而必须要进行窗口的合并。 
>
>     窗口的合并设计三个方面： 窗口对象的合并、State的合并和触发器的合并。

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20220824110254561.png" alt="image-20220824110254561" style="zoom:50%;" />

在Flink中提供4种Session Window的模型实现:

1. ProcessingTimeSessionWindows: 处理时间会话窗口，使用固定会话间隔时长。
2. DynamicProcessingTimeSessionWindows:处理时间会话窗口，使用自定义会话间隔。
3. EventTimeSessionWindows:事件时间会话窗口，使用固定会话间隔时长。
4. DynamicEventTimeSessionWindows:事件时间会话窗口，使用自定义会话间隔时长。

不同类型的会话窗口类型使用如下:

```java
DataStream<T> input = ...;

// event-time session windows with static gap
input
    .keyBy(<key selector>)
    .window(EventTimeSessionWindows.withGap(Time.minutes(10)))
    .<windowed transformation>(<window function>);
    
// event-time session windows with dynamic gap
input
    .keyBy(<key selector>)
    .window(EventTimeSessionWindows.withDynamicGap((element) -> {
        // determine and return session gap
    }))
    .<windowed transformation>(<window function>);

// processing-time session windows with static gap
input
    .keyBy(<key selector>)
    .window(ProcessingTimeSessionWindows.withGap(Time.minutes(10)))
    .<windowed transformation>(<window function>);
    
// processing-time session windows with dynamic gap
input
    .keyBy(<key selector>)
    .window(ProcessingTimeSessionWindows.withDynamicGap((element) -> {
        // determine and return session gap
    }))
    .<windowed transformation>(<window function>);
```



Static gaps can be specified by using one of `Time.milliseconds(x)`, `Time.seconds(x)`, `Time.minutes(x)`, and so on.

Dynamic gaps are specified by implementing the `SessionWindowTimeGapExtractor` interface.

> Since session windows do not have a fixed start and end, they are evaluated differently than tumbling and sliding windows. Internally, a session window operator creates a new window for each arriving record and merges windows together if they are closer to each other than the defined gap. In order to be mergeable, a session window operator requires a merging [Trigger](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#triggers) and a merging [Window Function](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#window-functions), such as `ReduceFunction`, `AggregateFunction`, or `ProcessWindowFunction`



##### 计算窗口

> ### Global Windows [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#global-windows)
>
> A *global windows* assigner assigns all elements with the same key to the same single *global window*. This windowing scheme is only useful if you also specify a custom [trigger](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/operators/windows/#triggers). Otherwise, no computation will be performed, as the global window does not have a natural end at which we could process the aggregated elements.

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20220824111407137.png" alt="image-20220824111407137" style="zoom:50%;" />

The following code snippets show how to use a global window.

```java
DataStream<T> input = ...;

input
    .keyBy(<key selector>)
    .window(GlobalWindows.create())
    .<windowed transformation>(<window function>);
```





# 三、水印

> 水印用于处理乱序事件、而正确地处理乱序事件，通常用Watermark机制结合窗口来实现。





##### 生成Watermark

> ## Using Watermark Strategies [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/generating_watermarks/#using-watermark-strategies)
>
> There are two places in Flink applications where a `WatermarkStrategy` can be used: 1) directly on sources and 2) after non-source operation.
>
> The first option is preferable, because it allows sources to exploit knowledge about shards/partitions/splits in the watermarking logic. Sources can usually then track watermarks at a finer level and the overall watermark produced by a source will be more accurate. Specifying a `WatermarkStrategy` directly on the source usually means you have to use a source specific interface/ Refer to [Watermark Strategies and the Kafka Connector](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/generating_watermarks/#watermark-strategies-and-the-kafka-connector) for how this works on a Kafka Connector and for more details about how per-partition watermarking works there.
>
> The second option (setting a `WatermarkStrategy` after arbitrary operations) should only be used if you cannot set a strategy directly on the source:



##### 生成机制

> 周期性机制：周期性Watermark策略在Flink中叫做PeriodicWatermarkAssigner，周期性低生成一个Watermark。在实际的生产中使用，使用watermark策略的时候，必须注意时间和数据量，结合时间和数据量考虑。
>
> 每事件Watermark机制: 数据流中每一个递增的EventTime都会产生一个Watermark。在实际的生产中Puncated方式在TPS很长的场景下回产生大量的Watermark，在一定程序下对下游算子造成压力，所有只有在实时性要求非常高的场景下，才会选择Puncated的方式进行watermark生产。





> ## Writing WatermarkGenerators [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/generating_watermarks/#writing-watermarkgenerators)
>
> A `TimestampAssigner` is a simple function that extracts a field from an event, we therefore don’t need to look at them in detail. A `WatermarkGenerator`, on the other hand, is a bit more complicated to write and we will look at how you can do that in the next two sections. This is the `WatermarkGenerator` interface:
>
> ```java
> /**
>  * The {@code WatermarkGenerator} generates watermarks either based on events or
>  * periodically (in a fixed interval).
>  *
>  * <p><b>Note:</b> This WatermarkGenerator subsumes the previous distinction between the
>  * {@code AssignerWithPunctuatedWatermarks} and the {@code AssignerWithPeriodicWatermarks}.
>  */
> @Public
> public interface WatermarkGenerator<T> {
> 
>     /**
>      * Called for every event, allows the watermark generator to examine 
>      * and remember the event timestamps, or to emit a watermark based on
>      * the event itself.
>      */
>     void onEvent(T event, long eventTimestamp, WatermarkOutput output);
> 
>     /**
>      * Called periodically, and might emit a new watermark, or not.
>      *
>      * <p>The interval in which this method is called and Watermarks 
>      * are generated depends on {@link ExecutionConfig#getAutoWatermarkInterval()}.
>      */
>     void onPeriodicEmit(WatermarkOutput output);
> }
> ```
>
> There are two different styles of watermark generation: *periodic* and *punctuated*.
>
> A periodic generator usually observes the incoming events via `onEvent()` and then emits a watermark when the framework calls `onPeriodicEmit()`.
>
> A puncutated generator will look at events in `onEvent()` and wait for special *marker events* or *punctuations* that carry watermark information in the stream. When it sees one of these events it emits a watermark immediately. Usually, punctuated generators don’t emit a watermark from `onPeriodicEmit()`.
>
> We will look at how to implement generators for each style next.  
>
> 
>
> ### Writing a Periodic WatermarkGenerator 
>
> A periodic generator observes stream events and generates watermarks periodically (possibly depending on the stream elements, or purely based on processing time).
>
> The interval (every *n* milliseconds) in which the watermark will be generated is defined via `ExecutionConfig.setAutoWatermarkInterval(...)`. The generators’s `onPeriodicEmit()` method will be called each time, and a new watermark will be emitted if the returned watermark is non-null and larger than the previous watermark.
>
> Here we show two simple examples of watermark generators that use periodic watermark generation. Note that Flink ships with `BoundedOutOfOrdernessWatermarks`, which is a `WatermarkGenerator` that works similarly to the `BoundedOutOfOrdernessGenerator` shown below. You can read about using that [here](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/built_in/).
>
> Java
>
> ```java
> /**
>  * This generator generates watermarks assuming that elements arrive out of order,
>  * but only to a certain degree. The latest elements for a certain timestamp t will arrive
>  * at most n milliseconds after the earliest elements for timestamp t.
>  */
> public class BoundedOutOfOrdernessGenerator implements WatermarkGenerator<MyEvent> {
> 
>     private final long maxOutOfOrderness = 3500; // 3.5 seconds
> 
>     private long currentMaxTimestamp;
> 
>     @Override
>     public void onEvent(MyEvent event, long eventTimestamp, WatermarkOutput output) {
>         currentMaxTimestamp = Math.max(currentMaxTimestamp, eventTimestamp);
>     }
> 
>     @Override
>     public void onPeriodicEmit(WatermarkOutput output) {
>         // emit the watermark as current highest timestamp minus the out-of-orderness bound
>         output.emitWatermark(new Watermark(currentMaxTimestamp - maxOutOfOrderness - 1));
>     }
> 
> }
> 
> /**
>  * This generator generates watermarks that are lagging behind processing time 
>  * by a fixed amount. It assumes that elements arrive in Flink after a bounded delay.
>  */
> public class TimeLagWatermarkGenerator implements WatermarkGenerator<MyEvent> {
> 
>     private final long maxTimeLag = 5000; // 5 seconds
> 
>     @Override
>     public void onEvent(MyEvent event, long eventTimestamp, WatermarkOutput output) {
>         // don't need to do anything because we work on processing time
>     }
> 
>     @Override
>     public void onPeriodicEmit(WatermarkOutput output) {
>         output.emitWatermark(new Watermark(System.currentTimeMillis() - maxTimeLag));
>     }
> }
> ```
>
> 
>
> 
>
> ### Writing a Punctuated WatermarkGenerator [#](https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/event-time/generating_watermarks/#writing-a-punctuated-watermarkgenerator)
>
> A punctuated watermark generator will observe the stream of events and emit a watermark whenever it sees a special element that carries watermark information.
>
> This is how you can implement a punctuated generator that emits a watermark whenever an event indicates that it carries a certain marker:
>
> Java
>
> ```java
> public class PunctuatedAssigner implements WatermarkGenerator<MyEvent> {
> 
>     @Override
>     public void onEvent(MyEvent event, long eventTimestamp, WatermarkOutput output) {
>         if (event.hasWatermarkMarker()) {
>             output.emitWatermark(new Watermark(event.getWatermarkTimestamp()));
>         }
>     }
> 
>     @Override
>     public void onPeriodicEmit(WatermarkOutput output) {
>         // don't need to do anything because we emit in reaction to events above
>     }
> }
> ```
>
> 



# 四、时间服务

