#kafka ack机制



在Producer向Kafka集群发送一条消息的时候，如果消息发送失败的话，并且我们设置了retries属性的话，Producer有重新发送消息的机制，这种机制主要是提高消息的发送成功率
如果我们想Producer发送的消息一定能发送成功，不会丢失的话，除了上面的消息重发机制，还有就是ack机制。  

一个topic可以分成多个partition，每一个partition可以有多个副本，在多个副本中有一个Leader副本和若干个Follower副本，Leader副本提供这个分区消息的读写服务  

如果Producer发送了一条消息，这个消息如果已经发送并存储在Leader副本中的日志文件中，那其实就可以说明这条消息已经发送成功了，但是如果这个Leader副本可能会挂掉，所以数据只存储在Leader副本也不能保证数据不会丢，所以有的时候Producer需要等到发送的消息都存储到ISR列表中的备份的时候才算成功，这个时候消息就不容易丢失了  

根据上面的特点，Producer在发送消息的时候就可以指定acks的值了，acks值可以是[ 0, 1, -1, all],如果是flume是没有all的


Producer在发送消息的时候就可以指定acks的值了，acks值可以是[ 0, 1, -1, all],如果是flume是没有all的

1.当acks=0的时候，Producer发送消息到发送端的buffer中就直接返回了，至于这个消息有没有真的发送到Broker Server，Producer不关心，即使消息发送失败，上面说的retry机制也不起作用，所以在这种场景下，可能就会丢失消息了(类似UDP,只管发,不管对方有没有接收到消息)  

2.当acks=1的时候，Producer发送的消息一定要存储到对应的分区的Leader副本日志文件中才算消息发送成功，要是失败的话，则会尝试retry。在这种场景下，只有当消息已经存储在Leader副本中，但是消息还没有被Follower副本同步的时候，如果Leader副本所在的broker server挂了，消息才会丢失  

3.当acks=-1或者等于all的时候，Producer发送的消息一定要存储到对应的分区的所有的在ISR列表中的副本日志文件中才算消息发送成功，要是失败的话，则会尝试retry。这种场景下消息就很难丢失了，除非所有的副本所在的Broker Server都挂了    
**ack = -1的时候，可能会出现数据重复的问题。**    
**当leadera数据同步完成后，没有发送给producer ack的时候，down 掉了。这个时候重新选择leader，这个时候，由于producer没有收到ack，会向新的leader重复发送数据，最终造成数据的重复问题。**


备注:
acks是英文单词acknowledgments的缩写，可以表示响应，即消息发送端发送消息给Kafka集群得到的响应，比如acks=all的时候，只有所有的ISR副本存储好消息之后才给客户端一个响应，表示消息存储成功
acks上面的三种取值可以根据你的业务需求来设置，消息的持久性是越来越强的，但是性能肯定越来越差的，上面的三种取值就是在消息持久性和性能两个方面做一个权衡(就像UDP和TCP,前者不管收不收到,只管发,这种性能肯定高,而TCP需要经过三次握手和四次挥手,以保证数据的传输,因此其性能肯定会比UDP差,所以,这个配置还是得看自己的业务场景)