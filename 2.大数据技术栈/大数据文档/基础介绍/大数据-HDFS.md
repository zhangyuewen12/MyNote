# HDFS基础介绍

## 1.引言 

### 1.1 什么是Hadoop？

Hadoop是一个开源的分布式计算框架，它是Apache基金会的一个顶级项目。它最初是由Doug Cutting和Mike Cafarella于2005年开发的，得名于Doug Cutting的儿子玩具大象“Hadoop”。

Hadoop的设计目标是能够高效地处理大规模数据集（通常是数TB或PB级别的数据）并能够在廉价的硬件上运行。它采用了分布式存储和计算的方式，将数据和计算任务分布到多个节点上，以实现横向扩展，从而具备良好的可扩展性和容错性。

Hadoop主要包含两个核心组件：

1. Hadoop分布式文件系统（HDFS）：是一种分布式存储系统，用于存储大规模数据集。它将数据划分为若干数据块，这些数据块会被复制到不同的节点上，以提供容错性和高可用性。

2. Hadoop分布式计算框架（MapReduce）：是一种分布式数据处理模型，用于在大规模数据集上进行并行计算。MapReduce模型将计算任务分为两个阶段：Map阶段和Reduce阶段，充分利用了集群中的计算资源来加速数据处理过程。

Hadoop不仅限于HDFS和MapReduce，它还有许多相关的项目和组件，如YARN（Yet Another Resource Negotiator，资源管理器）、Hive（一种类SQL查询工具）、HBase（一种分布式NoSQL数据库）等，这些项目组成了Hadoop生态系统，为用户提供了全面的大数据解决方案。

Hadoop已经成为大数据处理和存储的主流技术之一，在云计算、数据分析、人工智能等领域都得到广泛应用。它的开源性质使得全球的开发者能够共同贡献和改进，推动了大数据技术的不断发展和演进。

### 1.2 Hadoop的核心组件 

Hadoop的核心组件是指构成Hadoop分布式计算和存储基础架构的主要模块。这些组件共同协作，实现大规模数据的分布式存储、数据处理和计算。以下是Hadoop的核心组件：

1. Hadoop分布式文件系统（HDFS）：
   HDFS是Hadoop的存储层，用于存储大规模数据集。它将数据划分为固定大小的数据块，并将这些数据块分散地保存在Hadoop集群中的多个计算节点上。HDFS采用主从架构，其中一个节点是主节点（NameNode），负责管理文件系统的命名空间和数据块的位置信息，而其他节点是从节点（DataNode），用于存储实际的数据块。

2. Hadoop分布式计算框架（MapReduce）：
   MapReduce是Hadoop的计算层，用于在存储在HDFS上的数据集上进行并行计算。它的计算模型将任务分为两个阶段：Map阶段和Reduce阶段。在Map阶段，数据被分割并分发到集群中的多个节点上进行并行处理，生成中间键值对。然后，在Reduce阶段，中间键值对根据键进行合并和汇总，生成最终的计算结果。

3. YARN（Yet Another Resource Negotiator）：
   YARN是Hadoop的资源管理器，用于协调和管理Hadoop集群中的资源。它负责接收计算任务，监控集群资源使用情况，并将任务分配给合适的节点进行执行。**YARN支持多种计算框架，不仅仅限于MapReduce，使得Hadoop集群可以同时运行多种计算任务**，如Spark、Hive等。

4. Hadoop Common：
   Hadoop Common是Hadoop的公共库和工具集合，为Hadoop的其他组件提供了基础的支持。它包含一系列通用的API、工具和服务，用于处理分布式环境中的共性问题，如网络通信、认证、日志管理等。

除了上述核心组件外，Hadoop生态系统还有许多其他重要的组件和项目，如：
- Hive：基于Hadoop的数据仓库工具，用于支持类SQL查询和数据的转换与提取。
- HBase：一个分布式的NoSQL数据库，用于实时读写海量数据。
- Pig：用于数据流的编程语言和平台，简化了MapReduce任务的开发。
- Spark：一个快速、通用、内存计算的计算引擎，支持更多高级计算模式。
- ZooKeeper：用于分布式应用协调和管理的服务。

这些组件共同构成了Hadoop生态系统，为大数据处理和分析提供了丰富的工具和框架，使得Hadoop成为大规模数据处理和存储的主流解决方案。

### 1.3 HDFS的重要性

HDFS（Hadoop分布式文件系统）在Hadoop生态系统中扮演着至关重要的角色，它是Hadoop的存储层，负责存储大规模数据集。以下是HDFS的重要性：

1. 分布式数据存储：
   HDFS是一种分布式文件系统，它能够将大规模数据集分散地存储在Hadoop集群的多个节点上。数据被划分为固定大小的数据块，并且多个数据副本会被复制到不同的节点上，以实现数据的冗余存储和高可用性。这种分布式存储方式使得HDFS能够存储海量数据，从而满足大数据处理的需求。

2. 容错性和高可用性：
   HDFS的数据块复制策略保证了数据的容错性。每个数据块会根据配置的副本数（通常是3个）复制到不同的节点上。当某个节点发生故障时，HDFS可以自动从其他节点恢复数据，保障数据的可靠性和持续可用性。

3. 适合流式数据访问：
   HDFS对于大规模数据的读取和写入是高度优化的，特别适合批处理任务和流式数据访问。Hadoop的MapReduce计算框架和其他数据处理工具能够高效地利用HDFS的数据存储，实现并行的数据处理，从而加速数据分析和计算过程。

4. 适合大文件处理：
   **HDFS被设计用于处理大文件，而不是大量小文件**。它能够更有效地管理大文件的存储和访问，减少了文件系统的开销，提高了整体性能。

5. 高吞吐量：
   HDFS的设计目标之一是提供高吞吐量的数据访问。它通过数据块的复制和分布式计算的方式来并行处理大规模数据，从而实现了高并发的读写操作，能够支持多个数据处理任务同时进行。

6. 高扩展性：
   **HDFS的设计允许在需要时简单地增加计算节点和存储节点，从而实现系统的横向扩展。**这使得HDFS能够适应不断增长的数据存储需求，保证了系统的可扩展性。

综上所述，HDFS作为Hadoop生态系统的核心组件之一，为大数据处理和存储提供了稳健的解决方案。它的分布式、容错性、高可用性和高吞吐量等特性，使得HDFS成为了处理大规模数据集的首选存储方式，为Hadoop生态系统的其他组件和工具提供了强大的数据基础。

## 2.HDFS简介

### 2.1 HDFS概述

Hadoop分布式文件系统（HDFS）是Hadoop生态系统中的核心组件之一，是一个高度可扩展的、分布式的、容错性强的存储系统，旨在处理大规模数据集。HDFS的设计目标是能够在廉价的硬件上运行，并能够有效地管理和存储海量数据。以下是关于HDFS的详细介绍：

1. **分布式存储**：
   HDFS采用分布式存储方式，将数据划分为固定大小的数据块（通常为128MB或256MB），并将这些数据块分散地存储在Hadoop集群中的多个计算节点上。每个数据块会有多个副本（通常是3个），这些副本会被复制到不同的节点上，以实现数据的冗余存储和高可用性。

2. **主从架构**：
   HDFS采用主从架构，其中一个节点是主节点（NameNode），而其他节点是从节点（DataNode）。NameNode负责管理文件系统的命名空间、文件和数据块的元数据，它知道数据块位于哪些DataNode上。DataNode负责实际存储数据块。这种主从架构使得HDFS的元数据管理变得简单高效，同时降低了系统的复杂性。

3. **容错性和高可用性**：
   HDFS通过数据块的复制和主从架构实现了容错性和高可用性。每个数据块会被复制到不同的节点上，当某个DataNode发生故障时，数据仍然可从其他副本中恢复。同时，NameNode的元数据备份和热备份技术保证了元数据的可靠性和快速恢复，从而保障了系统的高可用性。

4. **适合大文件处理**：
   HDFS被设计用于处理大文件，而不是大量小文件。这是因为大文件能够更高效地利用数据块的复制和并行处理的特性，减少了文件系统的开销，提高了整体性能。

5. **高吞吐量**：
   HDFS的设计目标之一是提供高吞吐量的数据访问。它通过并行读写操作和数据块的分布式存储，能够支持多个数据处理任务同时进行，实现了高并发的数据访问，提高了数据处理的效率。

6. **自动数据负载均衡**：
   HDFS会自动管理数据的负载均衡，通过移动数据块和重新复制数据来确保集群中各节点存储的数据量基本均衡。这种机制使得整个集群的性能更加稳定，避免了出现热点节点导致的性能问题。

7. **与MapReduce紧密结合**：
   **HDFS与Hadoop分布式计算框架（MapReduce）紧密结合，共同构成了Hadoop生态系统。MapReduce任务可以直接从HDFS读取数据进行并行计算，并将计算结果写回HDFS。这种紧密结合使得HDFS成为大规模数据处理的理想存储解决方案。**

总结起来，HDFS是Hadoop生态系统的核心组件，具备分布式存储、容错性、高可用性、适合大文件处理和高吞吐量等特性。它为Hadoop集群提供了稳健的数据存储基础，使得Hadoop能够处理海量的数据，广泛应用于大数据处理、分析和存储等领域。

### 2.2 HDFS的设计目标

Hadoop分布式文件系统（HDFS）的设计目标是为了满足大规模数据处理的需求，它着重解决了传统文件系统在处理海量数据时面临的瓶颈和挑战。以下是HDFS的设计目标：

1. **适合海量数据存储：** HDFS被设计用于处理PB级别甚至更大规模的数据集，它采用分布式存储和分块处理的方式，能够有效地管理和存储海量数据。

2. **容错性和高可用性：** HDFS通过数据块的复制和主从架构实现了容错性和高可用性。每个数据块会被复制到不同的节点上，即使某个节点发生故障，数据仍然可从其他副本中恢复。同时，NameNode的元数据备份和热备份技术保证了元数据的可靠性和快速恢复，从而保障了系统的高可用性。

3. **数据局部性优化：** HDFS优化了数据局部性，即将数据存储在与计算节点相近的位置，从而减少数据的传输开销，提高了数据访问的性能。这对于MapReduce等计算框架来说尤为重要，能够最大程度地利用本地数据进行计算，减少数据的网络传输。

4. **高吞吐量：** HDFS的设计目标之一是提供高吞吐量的数据访问。它通过并行读写操作和数据块的分布式存储，能够支持多个数据处理任务同时进行，实现了高并发的数据访问，提高了数据处理的效率。

5. **简化硬件需求：** HDFS设计时考虑了在廉价的硬件上运行，降低了系统的硬件成本。相比传统的存储解决方案，HDFS更加适合在普通的廉价硬件上构建大规模集群，使得大规模数据处理更加经济和实用。

综上所述，HDFS的设计目标是针对大规模数据处理场景，提供容错性、适合海量数据存储、数据局部性优化、高吞吐量和简化硬件需求等特性。这些目标使得HDFS成为了大数据处理和存储的理想解决方案，并在Hadoop生态系统中扮演着至关重要的角色。

### 2.3 HDFS的特点

Hadoop分布式文件系统（HDFS）作为Hadoop生态系统的核心组件之一，具有许多特点，使其成为处理大规模数据的理想解决方案。以下是HDFS的特点：

1. **分布式存储：** HDFS采用分布式存储方式，将大规模数据集分散地存储在Hadoop集群的多个计算节点上。数据被划分为固定大小的数据块，并且多个数据副本会被复制到不同的节点上，以实现数据的冗余存储和高可用性。

2. **容错性和高可用性：** HDFS通过数据块的复制和主从架构实现了容错性和高可用性。每个数据块会根据配置的副本数（通常是3个）复制到不同的节点上，当某个节点发生故障时，HDFS可以自动从其他节点恢复数据，保障数据的可靠性和持续可用性。

3. **适合海量数据存储：** HDFS的设计目标之一是处理PB级别甚至更大规模的数据集。它通过分布式存储和分块处理的方式，能够有效地管理和存储海量数据，支持PB级别的数据存储需求。

4. **高吞吐量：** HDFS的设计目标之一是提供高吞吐量的数据访问。它通过并行读写操作和数据块的分布式存储，能够支持多个数据处理任务同时进行，实现了高并发的数据访问，提高了数据处理的效率。

5. **数据局部性优化：** HDFS优化了数据局部性，即将数据存储在与计算节点相近的位置，从而减少数据的传输开销，提高了数据访问的性能。这对于MapReduce等计算框架来说尤为重要，能够最大程度地利用本地数据进行计算，减少数据的网络传输。

6. **适合大文件处理：** HDFS被设计用于处理大文件，而不是大量小文件。它能够更有效地管理大文件的存储和访问，减少了文件系统的开销，提高了整体性能。

7. **自动数据负载均衡：** HDFS会自动管理数据的负载均衡，通过移动数据块和重新复制数据来确保集群中各节点存储的数据量基本均衡。这种机制使得整个集群的性能更加稳定，避免了出现热点节点导致的性能问题。

8. **可扩展性：** HDFS的设计允许在需要时简单地增加计算节点和存储节点，从而实现系统的横向扩展。这使得HDFS能够适应不断增长的数据存储需求，保证了系统的可扩展性。

9. **与MapReduce紧密结合：** HDFS与Hadoop分布式计算框架（MapReduce）紧密结合，共同构成了Hadoop生态系统。MapReduce任务可以直接从HDFS读取数据进行并行计算，并将计算结果写回HDFS。这种紧密结合使得HDFS成为大规模数据处理的理想存储解决方案。

综上所述，HDFS作为Hadoop生态系统的核心组件，具有分布式存储、容错性、高可用性、适合海量数据存储、高吞吐量、数据局部性优化等特点，为大数据处理和存储提供了强大的基础支持。它在大规模数据处理、分析和存储等领域得到广泛应用。

## 3.HDFS架构 

### 3.1 HDFS的主要组件

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20230801155430495.png" alt="image-20230801155430495" style="zoom:50%;" />

### 3.2 NameNode的角色和功能 

**NameNode（名称节点）：** NameNode是HDFS的主节点，负责管理文件系统的命名空间和元数据信息。元数据包括文件和目录的信息，如文件路径、数据块位置、访问权限等。NameNode维护了文件系统的整体结构，并且知道数据块在哪个DataNode上的位置。所有的元数据都保存在NameNode的内存中，因此NameNode的内存是HDFS性能的一个重要瓶颈。NameNode的高可用性和容错性非常重要，因此通常会采用热备份机制，其中有一个称为Secondary NameNode（辅助名称节点），负责定期从主NameNode上备份元数据，以便在主NameNode发生故障时快速恢复。

### 3.3 DataNode的角色和功能 

**DataNode（数据节点）：** DataNode是HDFS的从节点，负责存储实际的数据块。每个DataNode上都有一部分数据块的副本。DataNode定期向NameNode报告它所存储的数据块的信息，并接收来自NameNode的指令，如复制数据块或删除数据块。DataNode的数量通常是HDFS集群中最多的，它们分布在不同的计算节点上，共同存储整个HDFS中的数据。

### 3.4 Secondary NameNode的作用

**Secondary NameNode虽然名字中带有“Secondary”，但它并不是NameNode的备用节点。**Secondary NameNode的主要作用是辅助NameNode进行元数据的定期备份。它定期从NameNode上获取元数据的快照，并将其合并为一个新的fsimage（文件系统镜像）文件，然后将fsimage文件和最新的编辑日志（edits log）文件传输给NameNode。这样做的目的是为了减少NameNode启动时间，使得在NameNode发生故障时更快地恢复。

在Hadoop的HDFS中，Secondary NameNode并不是NameNode的备用节点，它不会在NameNode发生故障时自动接管成为新的NameNode，也不具备实时对NameNode的替代能力。相反，Secondary NameNode的主要功能是辅助NameNode进行元数据的定期备份。

为了理解这句话，我们需要知道Secondary NameNode的两个主要任务：

1. **辅助元数据备份：** Secondary NameNode定期从主NameNode上获取元数据的快照，并将其合并为一个新的fsimage（文件系统镜像）文件。然后，它将这个新的fsimage文件和最新的编辑日志（edits log）文件传输给主NameNode。这样做的目的是为了减少NameNode启动时间，使得在主NameNode发生故障时更快地恢复。
2. **辅助编辑日志合并：** 在HDFS中，NameNode在运行过程中会产生一些编辑日志，用于记录文件系统的变更操作，如文件的创建、删除、重命名等。这些编辑日志会不断增加，导致NameNode的内存占用不断增长。Secondary NameNode的另一个任务是帮助主NameNode将这些编辑日志合并，并清理已经应用的日志，从而减少NameNode的内存压力。

因此，虽然Secondary NameNode的名称中包含"Secondary"这个词，但它并不是NameNode的备用节点，它主要是为了协助NameNode进行元数据的备份和编辑日志的合并，从而提高NameNode的性能和容错性。NameNode本身的备份和故障转移通常是由其他机制和工具来实现，例如Hadoop高可用性（Hadoop High Availability，简称HA）方案。

#### 3.4.1 Secondary NameNode的元数据备份流程

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20230801153945998.png" alt="image-20230801153945998" style="zoom:50%;" />

1.集群启动 nameNode 节点下会生成 edit 操作日志和 fsImage 元数据文件镜像 两类数据磁盘备份, 并加载到内存中
2.客户端向 nameNode 请求对数据操作(增删改)
3.nameNode 想 edit 操作日志文件追加操作记录(增删改)
4.文件数据追加结束后, 将 nameNode 元数据进行修改
5.secondary NameNode 会定期检查 nameNode 中的 fsImage 和 edit 操作日志是否由于长时间追加操作导致数据量过大, 效率降低, (默认 edit 操作日志到达 100 万条, 请求 checkPoint 操作)
6.开始请求 checkPoint, 对元数据备份进行整理
7.nameNode 将 增加edit 操作日志, 后续操作追加到新的 edit 操作中, 防止数据整理, 不能对数据写的问题
8.nameNode 将 edit 操作日志和 fsImage 文件发送到 secondary NameNode
9.secondary NameNode 将 edit 操作日志和 fsImage 加载到内存合并
10.secondary NameNode 将内存中的数据写入到 fsImage.checkPoint文件中
11.secondary NameNode 将 fsImage.checkPoint 发送到 NameNode 中
12.NameNode 将 fsImage.checkPoint 重命名 fsImage 替换原来的 fsImage 文件

## 4.HDFS文件系统操作 

Hadoop分布式文件系统（HDFS）提供了一系列基础操作和命令，用于管理文件和目录。以下是HDFS的一些基础操作和常用命令：

1. **创建目录：** 使用`hdfs dfs -mkdir`命令可以创建目录。例如，要在HDFS上创建一个名为`/mydir`的目录，可以运行以下命令：

   ```
   hdfs dfs -mkdir /mydir
   ```

2. **上传文件：** 使用`hdfs dfs -put`命令可以将本地文件上传到HDFS。例如，要将本地文件`localfile.txt`上传到HDFS的`/mydir`目录下，可以运行以下命令：

   ```
   hdfs dfs -put localfile.txt /mydir/
   ```

3. **查看文件和目录：** 使用`hdfs dfs -ls`命令可以查看HDFS上的文件和目录。例如，要查看`/mydir`目录下的内容，可以运行以下命令：

   ```
   hdfs dfs -ls /mydir
   ```

4. **复制文件：** 使用`hdfs dfs -cp`命令可以复制HDFS上的文件。例如，要将`/mydir/file1.txt`复制到`/mydir/file2.txt`，可以运行以下命令：

   ```
   hdfs dfs -cp /mydir/file1.txt /mydir/file2.txt
   ```

5. **移动文件或重命名：** 使用`hdfs dfs -mv`命令可以移动文件或对文件进行重命名。例如，要将`/mydir/file1.txt`移动到`/mydir/newdir/file1.txt`，可以运行以下命令：

   ```
   hdfs dfs -mv /mydir/file1.txt /mydir/newdir/file1.txt
   ```

6. **下载文件：** 使用`hdfs dfs -get`命令可以将HDFS上的文件下载到本地文件系统。例如，要将HDFS上的`/mydir/file1.txt`下载到本地目录，可以运行以下命令：

   ```
   hdfs dfs -get /mydir/file1.txt localfile.txt
   ```

7. **删除文件：** 使用`hdfs dfs -rm`命令可以删除HDFS上的文件。例如，要删除`/mydir/file1.txt`，可以运行以下命令：

   ```
   hdfs dfs -rm /mydir/file1.txt
   ```

8. **删除目录：** 使用`hdfs dfs -rmdir`命令可以删除HDFS上的空目录。例如，要删除`/mydir`目录，前提是该目录为空，可以运行以下命令：

   ```
   hdfs dfs -rmdir /mydir
   ```

9. **删除目录及其内容：** 使用`hdfs dfs -rm -r`命令可以递归删除HDFS上的目录及其内容。例如，要删除`/mydir`目录及其所有内容，可以运行以下命令：

   ```
   hdfs dfs -rm -r /mydir
   ```

请注意，上述命令中的`hdfs dfs`是用于在命令行中与HDFS进行交互的前缀。在运行这些命令时，确保您的系统配置正确，并且Hadoop的相关服务已经启动。

## 5.HDFS数据复制

### 5.1 数据块概念 

在Hadoop分布式文件系统（HDFS）中，数据块（Block）是文件存储和管理的基本单位。HDFS将大文件分成固定大小的数据块进行存储，并将这些数据块分散地存储在HDFS集群的多个DataNode节点上。以下是HDFS中数据块的主要特点和概念：

1. **固定大小：**
   在HDFS中，数据块的大小通常是固定的，常见的默认大小是128MB或256MB。固定大小的数据块有助于提高数据的处理效率，避免了小文件导致的存储碎片问题，并且可以方便地进行数据块的切割和复制。

2. **分散存储：**
   大文件被分割成多个数据块，并分散地存储在HDFS集群的不同DataNode上。这样做的好处是可以并行读写大文件，提高数据的传输效率和处理能力。

3. **数据块副本：**
   为了保证数据的高可用性和容错性，HDFS会将每个数据块复制多个副本并分散存储在不同的DataNode上，默认情况下，数据块的副本数通常设置为3。如果某个DataNode发生故障，HDFS可以从其他副本中恢复数据，保证数据的可靠性。

4. **副本放置策略：**
   数据块的副本会尽可能地分布在不同的机架上，以提高数据的容错性。HDFS的副本放置策略通常是将副本放置在不同的机架、不同的机架内的不同DataNode上，并且会尽量保持在不同的存储节点上。

5. **块大小与磁盘存储：**
   数据块的大小对磁盘存储有影响。较大的数据块大小可以提高数据处理效率，减少磁盘寻址次数，但可能会导致小文件占用过多磁盘空间。较小的数据块大小可以减少存储碎片，但可能增加了数据的管理开销。因此，在选择数据块大小时，需要根据具体应用场景来进行权衡。

通过数据块的多副本机制，HDFS能够保证数据的高可用性和容错性。数据块的固定大小和分散存储特性使得HDFS能够处理大规模的数据，并且能够提供高吞吐量和高可靠性的分布式文件存储服务。

### 5.2 数据块的容错机制

Hadoop分布式文件系统（HDFS）中的数据块容错机制是保证数据可靠性和高可用性的关键部分。HDFS通过数据块的**多副本策略和故障处理机制来实现数据块**的容错。以下是HDFS中数据块的容错机制的主要内容：

1. **数据块多副本：**
   HDFS将每个数据块复制为多个副本，并将这些副本分散存储在HDFS集群的不同DataNode节点上。默认情况下，HDFS会为每个数据块创建3个副本。这种数据块的多副本策略保证了即使某个DataNode节点发生故障，数据仍然可以从其他节点上访问。

2. **副本放置策略：**
   HDFS的副本放置策略旨在确保数据的容错性和高可用性。副本放置策略通常遵循以下原则：
   - 一个副本存储在本地的DataNode节点上，即与数据块所属的客户端所在节点上，以减少数据访问时的网络开销。
   - 另外两个副本存储在不同的机架上，以防止整个机架故障。
   - 在不同机架内的DataNode节点上分散剩余的副本，尽量避免将所有副本放置在同一机架内。

3. **副本恢复和重平衡：**
   当某个DataNode节点发生故障或副本丢失时，HDFS会自动进行副本恢复。HDFS会从其他正常节点上选择合适的副本，并将丢失的副本重新复制到其他节点上，以确保数据的副本数量符合预设的要求。同时，HDFS还会对数据块进行重平衡，以保证集群中所有DataNode的负载均衡，提高集群整体性能。

4. **黑名单处理：**
   在检测到DataNode故障后，NameNode会将该DataNode列入黑名单，防止其他写操作向故障DataNode写入数据。这样可以保证数据写入的一致性，并防止在故障DataNode上产生更多的数据块副本。

**通过数据块的多副本策略和故障处理机制，HDFS能够有效地保证数据的高可用性和容错性。**即使在DataNode故障或数据块副本丢失的情况下，HDFS可以从其他副本中恢复数据，并确保数据可靠地存储在集群的多个节点上。这使得HDFS成为适合大规模数据存储和处理的可靠的分布式文件系统。

## 6.HDFS容错与恢复

### 6.1 NameNode的高可用性 

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20230801160802032.png" alt="image-20230801160802032" style="zoom:50%;" />

一个 NameNode 有单点问题，如果再提供一个 NameNode 作为备份，不是能解决问题？这便是**主备模式**的思想。继续这个思路，光有备份的 NameNode 够吗？我们知道 NameNode 上存储的是 HDFS 上所有的元数据信息，因此最关键的问题在于 NameNode 挂了一个，备份的要及时顶上，这就意味着我们要把所有的元数据都同步到备份节点。好，接下来我们考虑如何同步呢？每次 HDFS 写入一个文件，都要同步写 NameNode 和其备份节点吗？如果备份节点挂了就会写失败？显然不能这样，只能是异步来同步元数据。如果 NameNode 刚好宕机却没有将元数据异步写入到备份节点呢？那这部分信息岂不是丢失了？这个问题就自然要引入第三方的存储了，在 HA 方案中叫做“**共享存储**”。每次写文件时，需要将日志同步写入共享存储，这个步骤成功才能认定写文件成功。然后备份节点定期从共享存储同步日志，以便进行主备切换。

- Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。
- 主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。
- Zookeeper 集群：为主备切换控制器提供主备选举支持。
- 共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。Active NameNode 和 Standby NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。

可以看出，这里的核心是共享存储的实现，这些年有很多的 NameNode 共享存储方案，比如 Linux HA, VMware FT, shared NAS+NFS, BookKeeper, QJM/Quorum Journal Manager, BackupNode 等等。在关于共享存储设备的选择上，因为**NFS也会有单点故障问题，**目前社区已经把由 Clouderea 公司实现的基于 QJM（Quorum Journal Manager）的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现。

### **QJM**

基于 QJM 的共享存储系统主要用于**保存 EditLog，并不保存 FSImage 文件**。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20230801161217657.png" alt="image-20230801161217657" style="zoom:50%;" />

1. Active NameNode 提交 EditLog 到 JournalNode 集群
   Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。否则就认为提交 EditLog 失败，NameNode 停止服务退出进程。
2. Standby NameNode 从 JournalNode 集群同步 EditLog

虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。

### 6.2 DataNode故障处理

当HDFS集群中的某个DataNode发生故障时，HDFS需要进行相应的故障处理，以保证数据的可用性和高可靠性。以下是DataNode故障处理流程的主要步骤：

1. **检测DataNode故障：**
   HDFS中的NameNode会定期与所有DataNode保持心跳通信，如果某个DataNode在一定时间内没有收到心跳响应，则认为该DataNode发生了故障。

2. **副本丢失检测：**
   一旦检测到DataNode故障，NameNode会检查该DataNode上存储的数据块副本。如果某个数据块的所有副本都在故障的DataNode上，那么这个数据块就处于丢失状态，需要进行相应的处理。

3. **数据块复制：**
   当某个DataNode发生故障且数据块丢失时，HDFS会根据数据块的副本数量决定是否进行数据块复制。如果副本数量低于预设的副本数量，HDFS会启动数据块的复制过程，将丢失的副本重新复制到其他正常的DataNode上，以确保数据的可靠性。

4. **黑名单处理：**
   在检测到DataNode故障后，NameNode会将该DataNode列入黑名单，防止其他写操作向故障DataNode写入数据。这样可以保证数据写入的一致性，并防止在故障DataNode上产生更多的数据块副本。

5. **重新平衡：**
   一旦数据块副本已经复制到其他正常的DataNode上，HDFS会进行数据块的重新平衡，以保证集群中所有DataNode的负载均衡，从而提高集群整体性能。

6. **故障节点恢复：**
   在故障DataNode恢复后，它会重新连接到HDFS集群，并向NameNode报告自己的状态。NameNode会更新集群状态，并根据需要对数据块进行重新平衡。

通过以上故障处理流程，HDFS能够及时发现DataNode的故障，并对故障进行处理，从而保证数据的可靠性和高可用性。HDFS通过数据块的多副本机制，以及故障检测、副本复制和黑名单处理等策略，保证了数据的高可靠性和容错性，是一个适合海量数据存储和处理的分布式文件系统。

## 7.HDFS读写过程 

### 7.1 客户端写入数据过程 

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20230801160202085.png" alt="image-20230801160202085" style="zoom:50%;" />

HDFS客户端写入数据的过程涉及多个步骤，以下是HDFS客户端写入数据的详细过程：

1. **客户端连接：**
   客户端首先要与HDFS集群建立连接。它通过与NameNode通信获取元数据信息，包括文件的位置、数据块的副本数量、数据块在哪些DataNode上等。

2. **检查文件是否存在：**
   客户端会检查要写入的文件是否已经存在于HDFS中。如果文件已经存在且需要追加数据，客户端会继续在现有文件的末尾写入数据。如果文件不存在或不需要追加，则会创建新文件。

3. **数据划分：**
   客户端将要写入的数据划分为固定大小的数据块，通常默认大小为128MB或256MB。这些数据块将被分布式地存储在HDFS集群的多个DataNode上。

4. **选择目标DataNode：**
   客户端会根据文件的元数据信息选择合适的DataNode作为写入数据的目标节点。该DataNode将负责接收和处理客户端发送的数据块。

5. **数据写入：**
   客户端向目标DataNode发送数据写入请求。目标DataNode会接收客户端发送的数据块，并在本地磁盘上持久化存储这些数据块。同时，目标DataNode会将这些数据块的副本复制到其他DataNode上，以确保数据的可靠性和容错性。

6. **数据传输：**
   客户端通过与目标DataNode之间的直接通信进行数据传输。HDFS采用流式传输的方式，将数据块以流的形式传输给目标DataNode，这样可以降低数据传输的开销。

7. **副本写入：**
   目标DataNode接收到数据块后，会将数据块的副本复制到其他DataNode上，通常是复制到不同的机架上，以提高数据的容错性和可用性。

8. **数据块写入完成：**
   数据块的写入过程完成后，目标DataNode会向客户端发送确认消息，表示数据块写入成功。

9. **元数据更新：**
   客户端在写入所有数据块后，会通知NameNode更新文件的元数据信息，包括数据块的位置和副本数量等。

10. **文件写入完成：**
    当所有数据块都成功写入并元数据更新完成后，HDFS客户端认为文件写入过程已完成，客户端可以关闭与HDFS集群的连接。

整个HDFS客户端写入数据的过程通过与NameNode和DataNode的交互实现，客户端会根据文件的元数据信息选择合适的DataNode进行数据写入，同时通过数据块复制和副本写入来保证数据的可靠性和容错性。这种分布式的数据写入过程使得HDFS能够处理大规模的数据并提供高吞吐量和容错性。

### 7.2 客户端读取数据过程

<img src="/Users/zyw/Library/Application Support/typora-user-images/image-20230801160020825.png" alt="image-20230801160020825" style="zoom:50%;" />

HDFS客户端读取数据的过程涉及多个步骤，以下是HDFS客户端读取数据的详细过程：

1. **客户端连接：**
   客户端首先要与HDFS集群建立连接。它通过与NameNode通信获取元数据信息，包括文件的位置、数据块的副本数量、数据块在哪些DataNode上等。

2. **查找文件位置：**
   客户端根据文件路径从NameNode获取文件的元数据信息。NameNode会告知客户端该文件的数据块被复制到哪些DataNode上，并返回数据块的位置信息。

3. **获取数据块位置信息：**
   在客户端获取了文件的元数据信息后，它可以知道文件由哪些数据块组成，以及每个数据块的副本在哪些DataNode上。

4. **选择最近的DataNode：**
   客户端会根据网络距离选择距离最近的DataNode作为数据读取的目标节点。这样可以最大程度地减少数据的传输开销，提高读取性能。

5. **数据读取：**
   客户端向选择的DataNode发送数据读取请求。DataNode会根据请求返回对应数据块的内容。

6. **副本选择和故障处理：**
   如果某个DataNode在读取时发生故障，客户端会根据元数据信息找到该数据块的其他副本，并选择最近的可用DataNode作为备用节点，从而保证数据读取的高可用性和容错性。

7. **数据合并：**
   如果文件由多个数据块组成，客户端会从不同的DataNode上读取数据块内容，并将这些数据块内容合并为完整的文件内容。

8. **数据传输：**
   客户端通过与DataNode之间的直接通信进行数据传输。HDFS采用流式传输的方式，将数据块以流的形式传输给客户端，这样可以降低数据传输的开销。

9. **数据读取完成：**
   客户端读取数据块内容后，就可以在本地进行进一步的处理，如存储到本地文件系统或传递给应用程序进行处理。

HDFS客户端读取数据的过程中，客户端会根据文件的元数据信息和数据块的位置信息，选择最近的DataNode进行数据读取，以提高数据的读取性能和效率。如果某个DataNode发生故障，客户端会通过其他数据块副本来保证数据读取的可靠性和高可用性。整个过程通过与NameNode和DataNode的交互实现，从而实现对HDFS数据的有效读取。

## 8.HDFS的优缺点 

### 8.1 HDFS的优势 

1. **适合海量数据存储：** HDFS被设计用于处理PB级别甚至更大规模的数据集，它采用分布式存储和分块处理的方式，能够有效地管理和存储海量数据。
2. **容错性和高可用性：** HDFS通过数据块的复制和主从架构实现了容错性和高可用性。每个数据块会被复制到不同的节点上，即使某个节点发生故障，数据仍然可从其他副本中恢复。同时，NameNode的元数据备份和热备份技术保证了元数据的可靠性和快速恢复，从而保障了系统的高可用性。
3. **数据局部性优化：** HDFS优化了数据局部性，即将数据存储在与计算节点相近的位置，从而减少数据的传输开销，提高了数据访问的性能。这对于MapReduce等计算框架来说尤为重要，能够最大程度地利用本地数据进行计算，减少数据的网络传输。
4. **高吞吐量：** HDFS的设计目标之一是提供高吞吐量的数据访问。它通过并行读写操作和数据块的分布式存储，能够支持多个数据处理任务同时进行，实现了高并发的数据访问，提高了数据处理的效率。
5. **简化硬件需求：** HDFS设计时考虑了在廉价的硬件上运行，降低了系统的硬件成本。相比传统的存储解决方案，HDFS更加适合在普通的廉价硬件上构建大规模集群，使得大规模数据处理更加经济和实用。

### 8.2 HDFS的局限性

1. **不适合大量小文件：** HDFS在处理大量小文件时效率较低，这是因为每个文件占用至少一个数据块的存储空间，导致存储空间的浪费和元数据管理的复杂性。
2. **不支持实时数据访问：** HDFS适合用于离线数据处理和批处理任务，对于实时数据访问和低延迟的读写操作支持相对较差。对于需要实时查询和交互式分析的场景，通常需要结合其他组件，如Apache HBase或Apache Cassandra。
3. **单点故障：** HDFS的主从架构中，NameNode是单点故障（SPOF），如果NameNode发生故障，整个HDFS集群将不可用。虽然有Secondary NameNode来备份部分元数据，但它不能完全解决单点故障问题。
4. **复杂性：** HDFS的管理和维护相对复杂，特别是在大规模集群中，需要考虑数据块的复制、容错机制、负载均衡等问题。

尽管HDFS有一些局限性，但它作为Hadoop生态系统的关键组件，仍然在大规模数据处理和存储方面发挥着重要的作用。同时，Hadoop生态系统中也有其他的组件和项目，如HBase、Cassandra、Apache Spark等，用于弥补HDFS的一些局限性，提供更全面和多样化的解决方案。

## 9.HDFS在大数据生态系统中的角色 

### 9.1 HDFS与MapReduce的关系

HDFS与MapReduce密切关联，共同构成了Hadoop的基础架构。MapReduce任务可以直接从HDFS读取数据进行并行计算，并将计算结果写回HDFS。这种紧密结合使得HDFS成为大规模数据处理的理想存储解决方案，同时MapReduce能够高效地利用HDFS的分布式存储和数据局部性优化的特性，提高数据的处理效率。因此，HDFS和MapReduce是Hadoop的两个核心组件，它们共同协作，使得Hadoop能够处理海量的数据，支持大规模数据的存储和分布式计算，广泛应用于大数据处理、分析和存储等领域。除了MapReduce，HDFS也支持其他计算框架如Apache Spark等，这样更多的计算框架可以利用HDFS的数据存储和分布式计算能力。

### 9.2 HDFS与Hive的关系

1. **Hive的作用**： Hive是一个基于Hadoop的数据仓库工具，它提供了类SQL的查询语言，称为Hive Query Language（HQL），用于方便地进行数据的查询、转换和提取。Hive的设计目标是为了使非技术专家也能够轻松地进行大数据分析。Hive将HQL查询转换为一系列的MapReduce任务（或者其他计算框架，如Apache Tez），这些任务可以直接在Hadoop集群上运行，利用HDFS中存储的数据进行计算。

2. **HDFS与Hive的关系**： HDFS是Hive的默认存储和底层文件系统。Hive的表数据通常存储在HDFS上，Hive将表的数据划分为数据块并存储在HDFS的数据节点上。Hive的查询操作实际上是通过MapReduce任务或其他计算框架来处理存储在HDFS上的数据。因此，HDFS是Hive的主要数据存储和计算基础。

   HDFS的优势在于它能够处理大规模的数据，提供高吞吐量和容错性，这使得Hive能够处理大规模的数据集并进行复杂的分析任务。Hive利用HDFS的分布式存储和计算能力，可以在海量数据上进行高效的数据查询和分析。

   此外，Hive也支持其他存储格式和数据源，如HBase、S3等，这使得Hive具备更广泛的数据集成和分析能力。不过，无论是在默认情况下还是通过其他数据源，HDFS仍然是Hive的核心数据存储和计算基础，它与Hive紧密结合，为Hive提供了强大的数据存储和处理能力

## 10HDFS的最佳实践 

### 10.1 配置调优 

HDFS的配置调优是为了优化其性能和可靠性，使其在大规模数据处理中能够更高效地工作。以下是HDFS常用的配置调优策略：

1. **数据块大小调优**：
   HDFS将数据划分为固定大小的数据块，默认大小为128MB或256MB。数据块大小的选择会影响数据的存储和读写性能。较大的数据块大小有助于提高HDFS的吞吐量，但可能会增加数据的传输开销。在处理大文件时，较大的数据块大小通常更适合，而对于小文件，可以适当调小数据块大小，减少存储空间的浪费。

2. **副本数量调优**：
   HDFS存储数据块时会创建多个副本，通常设置为3个副本。副本数量的选择涉及到容错性和数据冗余的权衡。增加副本数量可以提高数据的容错性，但会增加存储开销。在高可用性要求较高的场景，可以考虑增加副本数量；而在存储成本较高的场景，可以适度减少副本数量。

3. **NameNode资源调优**：
   NameNode负责管理HDFS的元数据，对于大规模集群来说，NameNode可能成为性能瓶颈。可以通过增加NameNode的内存和CPU资源来提高其性能和承载能力。此外，还可以考虑使用高性能存储设备，如SSD，来提高NameNode的元数据读写速度。

4. **数据局部性优化**：
   数据局部性是指计算节点在进行数据处理时尽可能使用与其相近的数据，减少数据传输开销。可以通过调整HDFS的配置参数来优化数据局部性。例如，可以通过设置dfs.datanode.balance.bandwidthPerSec参数来调整数据块移动的速率，从而优化数据块的负载均衡。

5. **合理设置副本放置策略**：
   HDFS提供了不同的副本放置策略，如默认策略、机架感知策略等。合理设置副本放置策略可以优化数据块的复制和位置选择，从而提高数据的读取性能和容错性。

6. **压缩数据**：
   对于存储在HDFS上的数据，可以考虑采用压缩技术，将数据进行压缩存储，减少存储空间的占用，提高数据的传输效率。

7. **调整网络带宽和QoS设置**：
   优化HDFS集群节点间的网络带宽和质量服务（QoS）设置，确保数据传输在高速网络中进行，减少数据传输的瓶颈。

8. **定期清理过期数据和数据垃圾**：
   定期清理HDFS上过期的数据和垃圾数据，保持文件系统的整洁，减少不必要的存储和元数据开销。

以上策略是HDFS常用的配置调优方法，可以根据具体应用场景和集群规模进行调整和优化，以实现更高效的数据处理和存储。调优过程需要慎重进行，建议先进行测试和性能评估，确保调整后的配置能够在实际生产环境中发挥预期的效果。

